Name: [Aliza Makhani]
NetID: [am491]
Hours Spent: [10]
Consulted With: [Dr. Forbes]
Resources Used: [Java API, Stack Overflow]
Impressions: [It was fun, lots of concepts covered and very well rounded.]
%%%%
PROBLEM 1:
alice.txt, length = 163187;
For 2000 characters, the times respectively for orders 1, 5, and 10 are 0.875(±0.016), 0.549(±0.002), and 0.551(±0.000).
For 4000 characters, the times respectively for orders 1, 5, and 10 are 1.961(±0.007), 1.122(±0.001), and 1.095(±0.001).
For 8000 characters, the times respectively for orders 1, 5, and 10 are 3.909(±0.015), 2.212(±0.002), and 2.224(±0.003).
For 16000 characters, the times respectively for orders 1, 5, and 10 are 7.429(±0.002), 4.279(±0.001), and 4.270(±0.001).

hawthorne.txt, length = 496768:
For 2000 characters, the times respectively for orders 1, 5, and 10 are 2.799(±0.060), 1.584(±0.000), and 1.808(±0.047).
For 4000 characters, the times respectively for orders 1, 5, and 10 are 6.145(±0.024), 3.280(±0.002), and 3.244(±0.003).
For 8000 characters, the times respectively for orders 1, 5, and 10 are 11.001(±0.046), 5.727(±0.000), and 5.705(±0.003).
For 16000 characters, the times respectively for orders 1, 5, and 10 are 23.510(±0.867), 11.951(±0.002), and 11.759(±0.003).


%%%%
PROBLEM 2:
When the number of characters in the text increase by n times, so to do the run times. Alice.txt has roughly 1/3 of the number
of characters that Hawthorne.txt has, and the run times for Alice.txt are roughly 1/3 those of Hawthorne.txt. To generate
a 5-order Markov model for a text file with 5.5 million characters the mean time would be around 132. 
(5,500,000char/496,768char = 11.07*11.951 = 132.3). 

%%%%
PROBLEM 3:
alice.txt, length = 163187;
For 2000 characters, the times respectively for orders 1, 5, and 10 are 0.032(±0.001), 0.034(±0.000), and 0.050(±0.000).
For 4000 characters, the times respectively for orders 1, 5, and 10 are 0.010(±0.000), 0.034(±0.000), and 0.045(±0.000).
For 8000 characters, the times respectively for orders 1, 5, and 10 are 0.011(±0.010), 0.031(±0.000), and 0.053(±0.000).
For 16000 characters, the times respectively for orders 1, 5, and 10 are 0.014(±0.000), 0.037(±0.000), and 0.051(±0.000).

hawthorne.txt, length = 496768:
For 2000 characters, the times respectively for orders 1, 5, and 10 are 0.100(±0.007), 0.158(±0.001), and 0.227(±0.031).
For 4000 characters, the times respectively for orders 1, 5, and 10 are 0.035(±0.000), 0.120(±0.000), and 0.167(±0.000).
For 8000 characters, the times respectively for orders 1, 5, and 10 are 0.035(±0.000), 0.140(±0.000), and 0.171(±0.000).
For 16000 characters, the times respectively for orders 1, 5, and 10 are 0.038(±0.000), 0.131(±0.000), and 0.180(±0.000).

Using EfficientMarkov, when the size of the text file increases by n times, so to do the run times across the text files for 
any k-order Markov model. Within a text file, however, as the number of characters being generated increases the run times do
not increase -- they stay constant. Between a 1-order, 5-order, and 10-order model within one specified number of characters
being generated, the run times increase the most between a 1 and 5 order, but this rate of increase is much smaller between a
5 and 10 order. To generate a 5-order Markov model of 16000 characters from a file with 5.5million characters, the run time would 
be around 1.450. (5,500,000char/496,768char = 11.07*0.131 = 1.450)

%%%%
PROBLEM 4:
On average, there are 443 characters being generated with a 5-order model.

%%%%
PROBLEM 5:
In general, using a TreeMap in EfficientWordMarkov increases the run times compared to using a HashMap. For HashMaps, as size of the
training text increases by n times, so too do the runtimes for all order Markov processes. For TreeMaps, as size of the training
text increases by n times, the runtimes for all order Markov processes increase by 1.25n, so it is not necessarily 1 to 1. For
HashMaps and TreeMaps of a specific k-order Markov process, as the number of keys generated increases, the runtimes remain the same.
As k increases, there is a much larger increase in runtimes using a TreeMap than there is using a HashMap. For example, going from a 
1-order to 5-order model to 10-order using a TreeMap to generate 16000 characters from hawthorne.txt, the runtime goes from 0.086 to 
0.218 to 0.245 respectively. For a HashMap under the same conditions, the runtimes go from 0.028 to 0.037 to 0.048 for a 1 to 5 to 10
order model respectively.
%%%%
